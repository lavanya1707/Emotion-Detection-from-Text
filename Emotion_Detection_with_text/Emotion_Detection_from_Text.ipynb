{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18543230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9938c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4be14b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f3f31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_table('train.txt', delimiter = ';', header = None, )\n",
    "val = pd.read_table('val.txt', delimiter = ';', header = None, )\n",
    "test = pd.read_table('test.txt', delimiter = ';', header = None, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a98a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train, val, test])\n",
    "data.columns = ['text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67bec134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eed2b51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().any(axis = 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7534c216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text preprocessing\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess(line):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', line)      #leave only characters from a to z\n",
    "    review = review.lower()                      #lower the text\n",
    "    review = review.split()                      #turn string into list of words\n",
    "    \n",
    "    #apply stemming\n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]  #delete stop words\n",
    "    \n",
    "    #turn list into sentences\n",
    "    return \" \".join(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dec0eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data ['text'] = data['text'].apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0361740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "data['N_label'] = label_encoder.fit_transform(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1b6bf4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       didnt feel humili\n",
       "1       go feel hopeless damn hope around someon care ...\n",
       "2                    im grab minut post feel greedi wrong\n",
       "3          ever feel nostalg fireplac know still properti\n",
       "4                                            feel grouchi\n",
       "                              ...                        \n",
       "1995    keep feel like someon unkind wrong think get b...\n",
       "1996              im feel littl cranki neg doctor appoint\n",
       "1997                feel use peopl give great feel achiev\n",
       "1998    im feel comfort derbi feel though start step s...\n",
       "1999    feel weird meet w peopl text like dont talk fa...\n",
       "Name: text, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20f957af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 5000, ngram_range = (1,3))\n",
    "data_cv = cv.fit_transform(data['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92c465a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ec372f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_cv, data['N_label'], test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e78bb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 4s 1ms/step - loss: 1.0312 - accuracy: 0.6391\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2864 - accuracy: 0.9103\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1429 - accuracy: 0.9538\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0869 - accuracy: 0.9733\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0581 - accuracy: 0.9827\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0412 - accuracy: 0.9877\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0300 - accuracy: 0.9919\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0245 - accuracy: 0.9931\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0194 - accuracy: 0.9942\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0186 - accuracy: 0.9945\n",
      "469/469 [==============================] - 2s 2ms/step - loss: 0.0107 - accuracy: 0.9965\n",
      "Accuracy: 99.65\n"
     ]
    }
   ],
   "source": [
    "# first neural network with Keras tutorial\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np  # Make sure to import numpy for working with arrays\n",
    "\n",
    "# Define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# Compile the keras model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the keras model on the dataset\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=10)  # Corrected 'epoch' to 'epochs'\n",
    "\n",
    "# Evaluate the keras model\n",
    "_, accuracy = model.evaluate(x_train, y_train)\n",
    "print('Accuracy: %.2f' % (accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "996f806c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.7991 - accuracy: 0.8506\n",
      "accuracy: 85.06\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(x_test, y_test)\n",
    "print('accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81c58c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sadness'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'I feel sad'\n",
    "text = preprocess(text)\n",
    "array = cv.transform([text]).toarray()\n",
    "pred = model.predict(array)\n",
    "a = np.argmax(pred, axis=1)\n",
    "label_encoder.inverse_transform(a)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5510c1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lavanya\\AppData\\Local\\Temp\\ipykernel_20328\\676220079.py:1: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model, 'my_model.h5')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(model, 'my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3987ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(label_encoder, open('encoder.pkl','wb'))\n",
    "pickle.dump(cv, open('CountVectorizer.pkl','wb'))\n",
    "pickle.dump(preprocess, open('preprocess.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4993514b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef2f8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8540b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60715e23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
